{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argha/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/argha/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# NLTK for text cleaning\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords, names\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "# TextBlob package for translation and spelling correction\n",
    "from textblob import TextBlob\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "mallet_lda_topics={\n",
    "                0:'Hotel Staff',\n",
    "                1:'Accessibility',\n",
    "                2:'Food',\n",
    "                3:'Overall Experience',\n",
    "                4:'Noise',\n",
    "                5:'Value for Money',\n",
    "                6:'Room Amenities',\n",
    "                7:'Location in the city',\n",
    "                8:'Overall Experience',\n",
    "                9:'Cleanliness',\n",
    "                10:'Early Check-in/Late Check-out',\n",
    "                11:'Health and Wellness Amenities',\n",
    "                12:'Booking Experience',\n",
    "                13:'Sleep Quality',\n",
    "                14:'Parking Facility'\n",
    "            }\n",
    "\n",
    "\n",
    "def get_text(rev):\n",
    "    if pd.DataFrame(rev).empty:\n",
    "        return ''\n",
    "    else:\n",
    "        return rev[0] if str(rev)!='nan' else ''\n",
    "\n",
    "def review_cleaned(review_df):\n",
    "    df = review_df[['HotelName','PositiveReview','NegativeReview','StayDate']].copy()#.applymap(get_text)\n",
    "    df['FullReview'] = [pos+' '+neg for pos,neg in zip(df['PositiveReview'],df['NegativeReview'])]\n",
    "#     df['StayDate'] = df['StayDate'].apply(lambda x: x.replace('\\n','')).apply(lambda x: x.replace('Stayed in ',''))\n",
    "    return df\n",
    "\n",
    "def review_to_sentence(df):\n",
    "    all_sentences = []\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    import pandas as pd\n",
    "    allreview = df['FullReview']\n",
    "    for areview in allreview:\n",
    "        all_sentences.extend(sent_tokenize(areview))\n",
    "    tokensentence = pd.DataFrame(data=all_sentences,columns=['TokenSentence'])\n",
    "    return tokensentence\n",
    "\n",
    "def sentence_sentiment(text):\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    compound_sentiment = analyzer.polarity_scores(text)['compound']\n",
    "    return compound_sentiment\n",
    "\n",
    "def token_to_sentiment(df):\n",
    "    df['CompoundSentiment'] = df['TokenSentence'].apply(sentence_sentiment)\n",
    "    return df\n",
    "\n",
    "# helper functions for text preprocessing & LDA modeling:\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "\n",
    "    return token.is_punct or token.is_space or token.like_num or token.is_digit\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from Pandas Series\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "\n",
    "    #with codecs.open(filename, encoding='utf_8') as f:\n",
    "    for review in filename:\n",
    "        yield review.replace('\\\\n', '\\n')\n",
    "\n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "\n",
    "    for parsed_review in nlp.pipe(line_review(filename), batch_size=10000, n_threads=10):\n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])\n",
    "\n",
    "def trigram_bow_generator(filepath):\n",
    "    \"\"\"\n",
    "    generator function to read reviews from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    # load finished dictionary from disk\n",
    "    trigram_dictionary = Dictionary.load('/home/argha/Desktop/application/src/saved_model/models2/trigram_dict_all.dict')\n",
    "\n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(review)\n",
    "\n",
    "def nCPU():\n",
    "    import multiprocessing\n",
    "    N = multiprocessing.cpu_count()-1\n",
    "    return N\n",
    "\n",
    "def topic_extractor(df, min_topic_freq=0.10):\n",
    "    from tqdm import tqdm\n",
    "    from operator import itemgetter\n",
    "    ncpu = nCPU()\n",
    "    dfc=df.copy()\n",
    "    text = dfc['TokenSentence'].copy()\n",
    "    trigram_dictionary = Dictionary.load('/home/argha/Desktop/application/src/saved_model/models2/trigram_dict_all.dict')\n",
    "    lda = LdaMulticore.load('/home/argha/Desktop/application/src/saved_model/models2/mallet_lda_model')\n",
    "    # trigram_review = LineSentence('./tri_temporary.txt')\n",
    "    bigram_model = Phrases.load('/home/argha/Desktop/application/src/saved_model/models2/bigram_model.txt')\n",
    "    trigram_model = Phrases.load('/home/argha/Desktop/application/src/saved_model/models2/trigram_model.txt')\n",
    "    topic_list = []\n",
    "    trigram_list = []\n",
    "    freq_list = []\n",
    "    # parse the review text with spaCy\n",
    "    for parsed_review in tqdm(nlp.pipe(line_review(text),\n",
    "                                    batch_size=10000, n_threads=ncpu)):\n",
    "        # lemmatize the text, removing punctuation and whitespace\n",
    "        unigram_review = [token.lemma_ for token in parsed_review\n",
    "                            if not punct_space(token)]\n",
    "        # apply the first-order and second-order phrase models\n",
    "        bigram_review = bigram_model[unigram_review]\n",
    "        trigram_review = trigram_model[bigram_review]\n",
    "\n",
    "        common_terms = ['-PRON-','hotel'] #'service',\n",
    "        # remove any remaining stopwords\n",
    "        trigram_review = [term for term in trigram_review\n",
    "                            if term not in spacy.lang.en.stop_words.STOP_WORDS]\n",
    "        trigram_review = [term for term in trigram_review\n",
    "                            if term not in common_terms]\n",
    "        if len(trigram_review)==0:\n",
    "            topic_number=-1\n",
    "            freq = 0.0\n",
    "            tri = str([])\n",
    "        else:\n",
    "            # create a bag-of-words representation\n",
    "            review_bow = trigram_dictionary.doc2bow(trigram_review)\n",
    "            # create an LDA representation\n",
    "            review_lda = lda.get_document_topics(review_bow)\n",
    "            # print the most highly related topic name and frequency\n",
    "            review_lda = sorted(review_lda, key=itemgetter(1),reverse=True)[0]\n",
    "            topic_number = review_lda[0]\n",
    "            freq = review_lda[1]\n",
    "            if freq < min_topic_freq:\n",
    "                topic_number=-1\n",
    "                freq = 0.0\n",
    "\n",
    "        topic_list.append(topic_number)\n",
    "        freq_list.append(round(freq,2))\n",
    "        trigram_list.append(trigram_review)\n",
    "    dfc['Topic']=topic_list\n",
    "    dfc['TopicFrequency']=freq_list\n",
    "    dfc['Trigram']=trigram_list\n",
    "    return dfc\n",
    "\n",
    "def topic_scorer(df):\n",
    "    xdf = pd.get_dummies(df,prefix='Topic',\n",
    "                     prefix_sep='_', dummy_na=False,\n",
    "                     columns=['Topic'])\n",
    "    topics = ['Topic_0', 'Topic_1', 'Topic_2','Topic_3',\n",
    "              'Topic_4', 'Topic_5', 'Topic_6', 'Topic_7',\n",
    "              'Topic_8','Topic_9', 'Topic_10', 'Topic_11',\n",
    "              'Topic_12', 'Topic_13','Topic_14']\n",
    "    topic_dict = {}\n",
    "    for atopic in topics:\n",
    "        if atopic in xdf.columns.values:\n",
    "            xdf[atopic] = xdf[atopic] * xdf['CompoundSentiment']\n",
    "            m = list(filter(lambda a: a != 0, xdf[atopic]))\n",
    "            topic_dict[atopic] = round(np.mean(m),2)\n",
    "            topic_dict[atopic+'_scores'] = m\n",
    "        else:\n",
    "            topic_dict[atopic] = np.nan\n",
    "            topic_dict[atopic+'_scores'] = [np.nan]\n",
    "    return topic_dict\n",
    "\n",
    "def demo_(hotel_name):\n",
    "    new_doc = alldata[alldata['HotelName']==hotel_name]\n",
    "    # print(new_doc.shape)\n",
    "    text = review_cleaned(new_doc)\n",
    "    tokensentence = review_to_sentence(text)\n",
    "    sentencesentiment = token_to_sentiment(tokensentence)\n",
    "    topicdf = topic_extractor(sentencesentiment)\n",
    "    topic_dict = topic_scorer(topicdf)\n",
    "    topic_dict['HotelName']=hotel_name\n",
    "    return topic_dict#[(key,int(100*topic_dict[key])) for key in topic_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_json('/home/argha/Desktop/application/src/demo_data.json',orient='columns',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HotelName</th>\n",
       "      <th>PositiveReview</th>\n",
       "      <th>NegativeReview</th>\n",
       "      <th>StayDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612828</th>\n",
       "      <td>The Garland</td>\n",
       "      <td>Location and Great shuttle service to universa...</td>\n",
       "      <td>A little pricey for food and drinks at the hotel.</td>\n",
       "      <td>July 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503668</th>\n",
       "      <td>Sunset Marquis Hotel</td>\n",
       "      <td>Great position on Sunset strip, staff extremel...</td>\n",
       "      <td>Fee charged wi fi is nonsense in 2018, sorry.</td>\n",
       "      <td>December 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HotelName  \\\n",
       "612828           The Garland   \n",
       "503668  Sunset Marquis Hotel   \n",
       "\n",
       "                                           PositiveReview  \\\n",
       "612828  Location and Great shuttle service to universa...   \n",
       "503668  Great position on Sunset strip, staff extremel...   \n",
       "\n",
       "                                           NegativeReview       StayDate  \n",
       "612828  A little pricey for food and drinks at the hotel.      July 2017  \n",
       "503668      Fee charged wi fi is nonsense in 2018, sorry.  December 2018  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # mallet_lda_topics[int(atopic.replace('Topic_',''))]\n",
    "# hotel_names = alldata['HotelName'].unique()\n",
    "# topic_scores=[]\n",
    "# for hotel_name in tqdm(hotel_names):\n",
    "#     topic_scores.append(demo_(hotel_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(topic_scores).to_json('./topic_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_json('./topic_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HotelName</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>Topic_11</th>\n",
       "      <th>Topic_12</th>\n",
       "      <th>Topic_13</th>\n",
       "      <th>Topic_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelphi Hotel</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000 Islands Harbor Hotel</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HotelName  Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  \\\n",
       "0              Adelphi Hotel     0.69     0.72     0.77      NaN    -0.32   \n",
       "1  1000 Islands Harbor Hotel     0.71     0.74     0.46     0.55    -0.14   \n",
       "\n",
       "   Topic_5  Topic_6  Topic_7  Topic_8  Topic_9  Topic_10  Topic_11  Topic_12  \\\n",
       "0     0.65     0.60      NaN     0.42     0.40      0.06      0.79      0.55   \n",
       "1     0.60    -0.06     0.65     0.42    -0.08      0.41      0.63     -0.20   \n",
       "\n",
       "   Topic_13  Topic_14  \n",
       "0       NaN     -0.42  \n",
       "1      0.35     -0.24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ['HotelName','Topic_0', 'Topic_1', 'Topic_2','Topic_3',\n",
    "              'Topic_4', 'Topic_5', 'Topic_6', 'Topic_7',\n",
    "              'Topic_8','Topic_9', 'Topic_10', 'Topic_11',\n",
    "              'Topic_12', 'Topic_13','Topic_14']\n",
    "ddf[topics].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nystar = pd.read_json('/home/argha/Dropbox/data-files/hotel_info/NewYorkState_hotels_stars.json',encoding='utf-8', lines=True)\n",
    "# calistar = pd.read_json('/home/argha/Dropbox/data-files/hotel_info/CaliforniaState_hotels_stars.json',encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_text(rev):\n",
    "#     return rev[0] if str(rev)!='nan' else ''\n",
    "# def get_star(x):\n",
    "#     import re\n",
    "#     return re.sub(\"\\D\", \"\", x)\n",
    "\n",
    "# all_star = pd.concat([nystar,calistar],ignore_index=True)\n",
    "# all_star = all_star.applymap(get_text)\n",
    "# all_star['HotelStar'] = all_star['HotelStar'].apply(get_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_score_df = pd.merge(all_star,ddf,on='HotelName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_score_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(star_score_df).to_json('./hotel_star_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_score_df = pd.read_json('/home/argha/Dropbox/review-data/wk3/hotel_star_scores.json',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HotelID</th>\n",
       "      <th>HotelName</th>\n",
       "      <th>HotelStar</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_0_scores</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>Topic_10_scores</th>\n",
       "      <th>Topic_11</th>\n",
       "      <th>Topic_11_scores</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_5_scores</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_6_scores</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_7_scores</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_8_scores</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>Topic_9_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339211</td>\n",
       "      <td>Miami Motel</td>\n",
       "      <td></td>\n",
       "      <td>0.72</td>\n",
       "      <td>[0.8129000000000001, 0.742, 0.7184, 0.42150000...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.69</td>\n",
       "      <td>[0.4404, 0.5994, 0.5994, 0.5267000000000001, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>[0.6361, 0.8885000000000001, 0.8096, 0.8617, 0...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.33840000000000003, 0.8519, 0.6249, -0.5956]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.47</td>\n",
       "      <td>[0.4927, 0.3612, -0.4767, 0.7351000000000001, ...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[-0.1027, 0.40190000000000003]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HotelID    HotelName HotelStar  Topic_0  \\\n",
       "0  2339211  Miami Motel               0.72   \n",
       "\n",
       "                                      Topic_0_scores  Topic_1  Topic_10  \\\n",
       "0  [0.8129000000000001, 0.742, 0.7184, 0.42150000...     0.05       NaN   \n",
       "\n",
       "  Topic_10_scores  Topic_11  \\\n",
       "0              []      0.69   \n",
       "\n",
       "                                     Topic_11_scores  \\\n",
       "0  [0.4404, 0.5994, 0.5994, 0.5267000000000001, 0...   \n",
       "\n",
       "                ...                Topic_5  \\\n",
       "0               ...                   0.79   \n",
       "\n",
       "                                      Topic_5_scores  Topic_6  \\\n",
       "0  [0.6361, 0.8885000000000001, 0.8096, 0.8617, 0...      0.3   \n",
       "\n",
       "                                   Topic_6_scores  Topic_7 Topic_7_scores  \\\n",
       "0  [0.33840000000000003, 0.8519, 0.6249, -0.5956]      NaN         [None]   \n",
       "\n",
       "  Topic_8                                     Topic_8_scores Topic_9  \\\n",
       "0    0.47  [0.4927, 0.3612, -0.4767, 0.7351000000000001, ...    0.15   \n",
       "\n",
       "                   Topic_9_scores  \n",
       "0  [-0.1027, 0.40190000000000003]  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_score_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/argha/Dropbox/review-data/wk3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_compare(hotelname, star_rating):\n",
    "    topics = ['Topic_0', 'Topic_1', 'Topic_2','Topic_3',\n",
    "              'Topic_4', 'Topic_5', 'Topic_6', 'Topic_7',\n",
    "              'Topic_8','Topic_9', 'Topic_10', 'Topic_11',\n",
    "              'Topic_12', 'Topic_13','Topic_14']\n",
    "    mallet_lda_topics={\n",
    "                0:'Hotel Staff',\n",
    "                1:'Accessibility',\n",
    "                2:'Food',\n",
    "                3:'Overall Experience',\n",
    "                4:'Noise',\n",
    "                5:'Value for Money',\n",
    "                6:'Room Amenities',\n",
    "                7:'Location in the city',\n",
    "                8:'Overall Experience',\n",
    "                9:'Cleanliness',\n",
    "                10:'Early Check-in/Late Check-out',\n",
    "                11:'Health and Wellness Amenities',\n",
    "                12:'Booking Experience',\n",
    "                13:'Sleep Quality',\n",
    "                14:'Parking Facility'\n",
    "            }\n",
    "    df_myhotel = star_score_df[star_score_df['HotelName']==hotelname]\n",
    "    df = star_score_df[star_score_df['HotelStar']==str(star_rating)]\n",
    "    fig, ax = plt.subplots(figsize=(10, 60))\n",
    "    for i in range(len(topics)):\n",
    "        atopic = topics[i]\n",
    "        scores_dict = {}\n",
    "        if atopic in df_myhotel.columns.values:\n",
    "            myscore = 100.*float(df_myhotel[atopic])\n",
    "            otherscore = 100.*pd.Series(df[atopic].values, name = mallet_lda_topics[int(atopic.replace('Topic_',''))]).dropna()\n",
    "            othermean = 100.*np.mean(otherscore)\n",
    "            if myscore > othermean:\n",
    "                print(myscore)\n",
    "            \n",
    "            scores_dict[atopic] = [myscore,othermean]\n",
    "            plt.subplot(len(topics),1,i+1)\n",
    "            ax = sns.distplot(otherscore, color='y')\n",
    "            ax.axvline(myscore, 0,1.0);\n",
    "#         import seaborn as sns\n",
    "#         import pandas as pd\n",
    "#         fig, ax = plt.subplots(figsize=(10, 14))\n",
    "#         plt.subplot(2,1,1)\n",
    "#         x1 = pd.Series(s3['Topic_3'].values, name=\"Topic_3\").dropna()\n",
    "#         ax = sns.distplot(x1, color='y')\n",
    "#         ax.axvline(.38, 0,1.0);\n",
    "#         plt.subplot(2,1,2)\n",
    "#         x2 = pd.Series(s3['Topic_1'].values, name=\"Topic_1\").dropna()\n",
    "#         ax = sns.distplot(x2, color='y')\n",
    "#         ax.axvline(.8, 0,1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(hotel_name, hotel_star, atopic):\n",
    "    from io import StringIO\n",
    "    import base64\n",
    "    df_myhotel = star_score_df[star_score_df['HotelName']==hotel_name]\n",
    "    df = star_score_df[star_score_df['HotelStar']==str(hotel_star)]\n",
    "    myscore = 100.*float(df_myhotel[atopic])\n",
    "    otherscore = 100.*pd.Series(df[atopic].values, name = mallet_lda_topics[int(atopic.replace('Topic_',''))]).dropna()\n",
    "#     fig = StringIO()\n",
    "    sns.set_style(\"dark\") #E.G.\n",
    "    fig, ax = plt.subplots(figsize=(10, 10));\n",
    "    ax = sns.distplot(otherscore, color='y');\n",
    "    ax.axvline(myscore, 0,1.0);\n",
    "    \n",
    "    # Make Matplotlib write to BytesIO file object and grab\n",
    "    # return the object's string\n",
    "    from io import BytesIO\n",
    "    figfile = BytesIO()\n",
    "    fig.savefig(figfile, format='png')\n",
    "    figfile.seek(0)  # rewind to beginning of file\n",
    "    import base64\n",
    "    figdata_png = base64.b64encode(figfile.getvalue())\n",
    "    return figdata_png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_url = compare_plot('Adelphi Hotel',5,'Topic_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6bcaddde2d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
